{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "import os \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "import keras.utils\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"drive/My Drive/Train_Data/train_x.npy\")\n",
    "y_train = np.load(\"drive/My Drive/Train_Data/train_y.npy\")\n",
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(x_train)\n",
    "train_std = np.std(x_train)\n",
    "x_train = (x_train - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tensorflow.keras.utils.to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_classes = 3\n",
    "epochs = 50\n",
    "img_x, img_y = 512, 512\n",
    "input_shape = (img_x, img_y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_WEIGHTS_PATH = (\n",
    "    'https://github.com/fchollet/deep-learning-models/'\n",
    "    'releases/download/v0.4/'\n",
    "    'xception_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "TF_WEIGHTS_PATH_NO_TOP = (\n",
    "    'https://github.com/fchollet/deep-learning-models/'\n",
    "    'releases/download/v0.4/'\n",
    "    'xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "\n",
    "def Xception(include_top=True,\n",
    "             weights='imagenet',\n",
    "             input_tensor=None,\n",
    "             input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000,\n",
    "             **kwargs):\n",
    "    \"\"\"Instantiates the Xception architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    Note that the default input image size for this model is 299x299.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(299, 299, 3)`.\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 71.\n",
    "            E.g. `(150, 150, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional block.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional block, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True,\n",
    "            and if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "        RuntimeError: If attempting to run this model with a\n",
    "            backend that does not support separable convolutions.\n",
    "    \"\"\"\n",
    "    \n",
    "    channel_axis = -1\n",
    "\n",
    "    img_input=layers.Input(input_shape)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      use_bias=False,\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block1_conv1_act')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block1_conv2_bn')(x)\n",
    "    x = layers.Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "    residual = layers.Conv2D(128, (1, 1),\n",
    "                             strides=(2, 2),\n",
    "                             padding='same',\n",
    "                             use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.SeparableConv2D(128, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block2_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block2_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(128, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block2_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block2_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3),\n",
    "                            strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block2_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    residual = layers.Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                             padding='same', use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.Activation('relu', name='block3_sepconv1_act')(x)\n",
    "    x = layers.SeparableConv2D(256, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block3_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block3_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(256, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block3_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block3_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block3_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    residual = layers.Conv2D(728, (1, 1),\n",
    "                             strides=(2, 2),\n",
    "                             padding='same',\n",
    "                             use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.Activation('relu', name='block4_sepconv1_act')(x)\n",
    "    x = layers.SeparableConv2D(728, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block4_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block4_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(728, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block4_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block4_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block4_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    for i in range(8):\n",
    "        residual = x\n",
    "        prefix = 'block' + str(i + 5)\n",
    "\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
    "        x = layers.SeparableConv2D(728, (3, 3),\n",
    "                                   padding='same',\n",
    "                                   use_bias=False,\n",
    "                                   name=prefix + '_sepconv1')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      name=prefix + '_sepconv1_bn')(x)\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
    "        x = layers.SeparableConv2D(728, (3, 3),\n",
    "                                   padding='same',\n",
    "                                   use_bias=False,\n",
    "                                   name=prefix + '_sepconv2')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      name=prefix + '_sepconv2_bn')(x)\n",
    "        x = layers.Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
    "        x = layers.SeparableConv2D(728, (3, 3),\n",
    "                                   padding='same',\n",
    "                                   use_bias=False,\n",
    "                                   name=prefix + '_sepconv3')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      name=prefix + '_sepconv3_bn')(x)\n",
    "\n",
    "        x = layers.add([x, residual])\n",
    "\n",
    "    residual = layers.Conv2D(1024, (1, 1), strides=(2, 2),\n",
    "                             padding='same', use_bias=False)(x)\n",
    "    residual = layers.BatchNormalization(axis=channel_axis)(residual)\n",
    "\n",
    "    x = layers.Activation('relu', name='block13_sepconv1_act')(x)\n",
    "    x = layers.SeparableConv2D(728, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block13_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block13_sepconv2_act')(x)\n",
    "    x = layers.SeparableConv2D(1024, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block13_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block13_sepconv2_bn')(x)\n",
    "\n",
    "    x = layers.MaxPooling2D((3, 3),\n",
    "                            strides=(2, 2),\n",
    "                            padding='same',\n",
    "                            name='block13_pool')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = layers.SeparableConv2D(1536, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block14_sepconv1')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv1_bn')(x)\n",
    "    x = layers.Activation('relu', name='block14_sepconv1_act')(x)\n",
    "\n",
    "    x = layers.SeparableConv2D(2048, (3, 3),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               name='block14_sepconv2')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, name='block14_sepconv2_bn')(x)\n",
    "    x = layers.Activation('relu', name='block14_sepconv2_act')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras.utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='xception')\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = keras.utils.get_file(\n",
    "                'xception_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                TF_WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                file_hash='0a58e3b7378bc2990ea3b43d5981f1f6')\n",
    "        else:\n",
    "            weights_path = keras.utils.get_file(\n",
    "                'xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                TF_WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                file_hash='b0042744bf5b25fce3cb969f33bebb97')\n",
    "        model.load_weights(weights_path)\n",
    "        if backend.backend() == 'theano':\n",
    "            keras.utils.convert_all_kernels_in_model(model)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(weights='imagenet', input_shape=(512, 512, 3),include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning - Pre Training + Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "inputs = tensorflow.keras.Input(shape=(512, 512, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "outputs = x\n",
    "model = tensorflow.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size,class_weight=class_weight_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
