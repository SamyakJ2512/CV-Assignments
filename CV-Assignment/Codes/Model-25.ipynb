{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "import os \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "import keras.utils\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Augmented Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"drive/My Drive/Aug_Train_Data/train_x.npy\")\n",
    "y_train = np.load(\"drive/My Drive/Aug_Train_Data/train_y.npy\")\n",
    "from sklearn.utils import shuffle\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tensorflow.keras.utils.to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_classes = 3\n",
    "epochs = 50\n",
    "img_x, img_y = 512, 512\n",
    "input_shape = (img_x, img_y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of\n",
    "            middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size,\n",
    "                      padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_ResNet(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2)):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of\n",
    "            middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "        strides: Strides for the first conv layer in the block.\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3,\n",
    "    the first conv layer at main path is with strides=(2, 2)\n",
    "    And the shortcut should have strides=(2, 2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(filters1, (1, 1), strides=strides,\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2a')(input_tensor)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters2, kernel_size, padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2b')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters3, (1, 1),\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name=conv_name_base + '2c')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = layers.Conv2D(filters3, (1, 1), strides=strides,\n",
    "                             kernel_initializer='he_normal',\n",
    "                             name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = layers.BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet50(include_top=True,\n",
    "             weights='imagenet',\n",
    "             input_tensor=None,\n",
    "             input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000,\n",
    "             **kwargs):\n",
    "    \"\"\"Instantiates the ResNet50 architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional block.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional block, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    bn_axis = 3\n",
    "    img_input=layers.Input(input_shape)\n",
    "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(64, (7, 7),\n",
    "                      strides=(2, 2),\n",
    "                      padding='valid',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      name='conv1')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block_ResNet(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block_ResNet(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    x = conv_block_ResNet(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    x = conv_block_ResNet(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "        else:\n",
    "            warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
    "                          'has been changed since Keras 2.2.0.')\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='resnet50')\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'resnet50_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='a7b3fe01876f51b976af0dea6bc144eb')\n",
    "        else:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='a268eb855778b3df3c7506639542a6af')\n",
    "        model.load_weights(weights_path)\n",
    "        if backend.backend() == 'theano':\n",
    "            keras_utils.convert_all_kernels_in_model(model)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(x, blocks, name):\n",
    "    \"\"\"A dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        blocks: integer, the number of building blocks.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    for i in range(blocks):\n",
    "        x = conv_block_DenseNet(x, 32, name=name + '_block' + str(i + 1))\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, reduction, name):\n",
    "    \"\"\"A transition block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        reduction: float, compression rate at transition layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 \n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                  name=name + '_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_relu')(x)\n",
    "    x = layers.Conv2D(int(backend.int_shape(x)[bn_axis] * reduction), 1,\n",
    "                      use_bias=False,\n",
    "                      name=name + '_conv')(x)\n",
    "    x = layers.AveragePooling2D(2, strides=2, name=name + '_pool')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_DenseNet(x, growth_rate, name):\n",
    "    \"\"\"A building block for a dense block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        growth_rate: float, growth rate at dense layers.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 \n",
    "    x1 = layers.BatchNormalization(axis=bn_axis,\n",
    "                                   epsilon=1.001e-5,\n",
    "                                   name=name + '_0_bn')(x)\n",
    "    x1 = layers.Activation('relu', name=name + '_0_relu')(x1)\n",
    "    x1 = layers.Conv2D(4 * growth_rate, 1,\n",
    "                       use_bias=False,\n",
    "                       name=name + '_1_conv')(x1)\n",
    "    x1 = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                   name=name + '_1_bn')(x1)\n",
    "    x1 = layers.Activation('relu', name=name + '_1_relu')(x1)\n",
    "    x1 = layers.Conv2D(growth_rate, 3,\n",
    "                       padding='same',\n",
    "                       use_bias=False,\n",
    "                       name=name + '_2_conv')(x1)\n",
    "    x = layers.Concatenate(axis=bn_axis, name=name + '_concat')([x, x1])\n",
    "    return x\n",
    "\n",
    "\n",
    "def DenseNet(blocks,\n",
    "             include_top=True,\n",
    "             weights='imagenet',\n",
    "             input_tensor=None,\n",
    "             input_shape=None,\n",
    "             pooling=None,\n",
    "             classes=1000,\n",
    "             **kwargs):\n",
    "    \"\"\"Instantiates the DenseNet architecture.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        blocks: numbers of building blocks for the four dense layers.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `'channels_last'` data format)\n",
    "            or `(3, 224, 224)` (with `'channels_first'` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 32.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional block.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional block, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    \n",
    "    bn_axis = 3 \n",
    "    img_input=layers.Input(input_shape)\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=False, name='conv1/conv')(x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='conv1/bn')(x)\n",
    "    x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "\n",
    "    x = dense_block(x, blocks[0], name='conv2')\n",
    "    x = transition_block(x, 0.5, name='pool2')\n",
    "    x = dense_block(x, blocks[1], name='conv3')\n",
    "    x = transition_block(x, 0.5, name='pool3')\n",
    "    x = dense_block(x, blocks[2], name='conv4')\n",
    "    x = transition_block(x, 0.5, name='pool4')\n",
    "    x = dense_block(x, blocks[3], name='conv5')\n",
    "\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis, epsilon=1.001e-5, name='bn')(x)\n",
    "    x = layers.Activation('relu', name='relu')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='fc1000')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    if blocks == [6, 12, 24, 16]:\n",
    "        model = models.Model(inputs, x, name='densenet121')\n",
    "    elif blocks == [6, 12, 32, 32]:\n",
    "        model = models.Model(inputs, x, name='densenet169')\n",
    "    elif blocks == [6, 12, 48, 32]:\n",
    "        model = models.Model(inputs, x, name='densenet201')\n",
    "    else:\n",
    "        model = models.Model(inputs, x, name='densenet')\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            if blocks == [6, 12, 24, 16]:\n",
    "                weights_path = keras_utils.get_file(\n",
    "                    'densenet121_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                    DENSENET121_WEIGHT_PATH,\n",
    "                    cache_subdir='models',\n",
    "                    file_hash='9d60b8095a5708f2dcce2bca79d332c7')\n",
    "            elif blocks == [6, 12, 32, 32]:\n",
    "                weights_path = keras_utils.get_file(\n",
    "                    'densenet169_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                    DENSENET169_WEIGHT_PATH,\n",
    "                    cache_subdir='models',\n",
    "                    file_hash='d699b8f76981ab1b30698df4c175e90b')\n",
    "            elif blocks == [6, 12, 48, 32]:\n",
    "                weights_path = keras_utils.get_file(\n",
    "                    'densenet201_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                    DENSENET201_WEIGHT_PATH,\n",
    "                    cache_subdir='models',\n",
    "                    file_hash='1ceb130c1ea1b78c3bf6114dbdfd8807')\n",
    "        else:\n",
    "            if blocks == [6, 12, 24, 16]:\n",
    "                weights_path = keras_utils.get_file(\n",
    "                    'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                    DENSENET121_WEIGHT_PATH_NO_TOP,\n",
    "                    cache_subdir='models',\n",
    "                    file_hash='30ee3e1110167f948a6b9946edeeb738')\n",
    "            elif blocks == [6, 12, 32, 32]:\n",
    "                weights_path = keras_utils.get_file(\n",
    "                    'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                    DENSENET169_WEIGHT_PATH_NO_TOP,\n",
    "                    cache_subdir='models',\n",
    "                    file_hash='b8c4d4c20dd625c148057b9ff1c1176b')\n",
    "            elif blocks == [6, 12, 48, 32]:\n",
    "                weights_path = keras_utils.get_file(\n",
    "                    'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                    DENSENET201_WEIGHT_PATH_NO_TOP,\n",
    "                    cache_subdir='models',\n",
    "                    file_hash='c13680b51ded0fb44dff2d8f86ac8bb1')\n",
    "        model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def DenseNet121(include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000,\n",
    "                **kwargs):\n",
    "    return DenseNet([6, 12, 24, 16],\n",
    "                    include_top, weights,\n",
    "                    input_tensor, input_shape,\n",
    "                    pooling, classes,\n",
    "                    **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble of DenseNet and ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = DenseNet121(weights=None, input_shape=(512, 512, 3),include_top=False)\n",
    "model1  = Sequential()\n",
    "model1.add(base_model1)\n",
    "\n",
    "base_model2 = ResNet50(weights=None, input_shape=(512, 512, 3),include_top=False)\n",
    "model2  = Sequential()\n",
    "model2.add(base_model2)\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "x = concatenate([model1.output, model2.output], axis=-1)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "outputs = x\n",
    "model = Model(inputs=[model1.input, model2.input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_train,x_train],y_train,epochs=epochs,batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
